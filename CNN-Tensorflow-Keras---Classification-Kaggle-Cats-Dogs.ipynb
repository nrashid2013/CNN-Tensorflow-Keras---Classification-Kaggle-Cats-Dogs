{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"C:/script/python/MachineLearning/Main/SDeepLearningTensorFlowKeras/Pets/PetImages/\"\n",
    "CATEGORIES = [\"Dog\", \"Cat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "\n",
    "IMG_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category)\n",
    "        print(path)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img),  cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                training_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/script/python/MachineLearning/Main/SDeepLearningTensorFlowKeras/Pets/PetImages/Dog\n",
      "C:/script/python/MachineLearning/Main/SDeepLearningTensorFlowKeras/Pets/PetImages/Cat\n"
     ]
    }
   ],
   "source": [
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24946\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(training_data)\n",
    "for sample in training_data[:10]:\n",
    "    print(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 32]\n",
      "  [ 23]\n",
      "  [ 29]\n",
      "  ...\n",
      "  [109]\n",
      "  [ 62]\n",
      "  [ 94]]\n",
      "\n",
      " [[ 40]\n",
      "  [116]\n",
      "  [ 74]\n",
      "  ...\n",
      "  [ 78]\n",
      "  [ 80]\n",
      "  [ 91]]\n",
      "\n",
      " [[238]\n",
      "  [138]\n",
      "  [115]\n",
      "  ...\n",
      "  [119]\n",
      "  [111]\n",
      "  [249]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 43]\n",
      "  [ 85]\n",
      "  [ 81]\n",
      "  ...\n",
      "  [ 56]\n",
      "  [ 59]\n",
      "  [246]]\n",
      "\n",
      " [[ 62]\n",
      "  [ 57]\n",
      "  [ 24]\n",
      "  ...\n",
      "  [ 72]\n",
      "  [159]\n",
      "  [244]]\n",
      "\n",
      " [[ 39]\n",
      "  [ 29]\n",
      "  [ 58]\n",
      "  ...\n",
      "  [ 71]\n",
      "  [221]\n",
      "  [242]]]\n"
     ]
    }
   ],
   "source": [
    "pickle_in = open(\"X.pickle\", \"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "print(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "pickle_in = open(\"y.pickle\", \"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "print(y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 8s 466us/sample - loss: 0.6327 - acc: 0.6349 - val_loss: 0.5661 - val_acc: 0.7104\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 8s 438us/sample - loss: 0.5306 - acc: 0.7342 - val_loss: 0.5110 - val_acc: 0.7473\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 8s 447us/sample - loss: 0.4695 - acc: 0.7759 - val_loss: 0.4787 - val_acc: 0.7682\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 8s 440us/sample - loss: 0.4223 - acc: 0.8062 - val_loss: 0.4940 - val_acc: 0.7652\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 8s 450us/sample - loss: 0.3776 - acc: 0.8285 - val_loss: 0.4727 - val_acc: 0.7722\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 8s 432us/sample - loss: 0.3290 - acc: 0.8564 - val_loss: 0.4755 - val_acc: 0.7878\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 8s 438us/sample - loss: 0.2732 - acc: 0.8836 - val_loss: 0.5305 - val_acc: 0.7791\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 8s 439us/sample - loss: 0.2153 - acc: 0.9107 - val_loss: 0.5797 - val_acc: 0.7783\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 8s 437us/sample - loss: 0.1635 - acc: 0.9388 - val_loss: 0.6206 - val_acc: 0.7819\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 8s 444us/sample - loss: 0.1157 - acc: 0.9562 - val_loss: 0.7052 - val_acc: 0.7821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x199890445f8>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=32, epochs=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME =  \"Cats-vs-dogs-cnn-{}\".format(int(time.time()))\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/3\n",
      "17462/17462 [==============================] - 8s 436us/sample - loss: 0.6513 - acc: 0.6136 - val_loss: 0.6225 - val_acc: 0.6527\n",
      "Epoch 2/3\n",
      "17462/17462 [==============================] - 7s 401us/sample - loss: 0.5794 - acc: 0.7011 - val_loss: 0.5680 - val_acc: 0.7035\n",
      "Epoch 3/3\n",
      "17462/17462 [==============================] - 7s 402us/sample - loss: 0.5293 - acc: 0.7424 - val_loss: 0.5150 - val_acc: 0.7448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x199893aa588>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "# model.add(Dense(64))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, batch_size=32, epochs=3, validation_split=0.3, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense_layers = [0,1,2]\n",
    "# layer_sizes = [32, 64, 128]\n",
    "# conv_layers = [1, 2, 3]\n",
    "#\n",
    "# for dense_layer in dense_layers:\n",
    "#     for layer_size in layer_sizes:\n",
    "#         for conv_layer in conv_layers:\n",
    "#             NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "#             print(NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layers = [0, 1, 2]\n",
    "layer_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-conv-32-nodes-0-dense-1569281649\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/3\n",
      "17462/17462 [==============================] - 2s 143us/sample - loss: 0.6226 - acc: 0.6523 - val_loss: 0.5843 - val_acc: 0.7022\n",
      "Epoch 2/3\n",
      "17462/17462 [==============================] - 2s 124us/sample - loss: 0.5663 - acc: 0.7121 - val_loss: 0.5580 - val_acc: 0.7159\n",
      "Epoch 3/3\n",
      "17462/17462 [==============================] - 2s 127us/sample - loss: 0.5275 - acc: 0.7426 - val_loss: 0.5657 - val_acc: 0.7032\n",
      "2-conv-32-nodes-0-dense-1569281663\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/3\n",
      "17462/17462 [==============================] - 3s 179us/sample - loss: 0.6406 - acc: 0.6286 - val_loss: 0.5960 - val_acc: 0.6832\n",
      "Epoch 2/3\n",
      "17462/17462 [==============================] - 3s 149us/sample - loss: 0.5520 - acc: 0.7219 - val_loss: 0.5260 - val_acc: 0.7397\n",
      "Epoch 3/3\n",
      "17462/17462 [==============================] - 3s 145us/sample - loss: 0.5028 - acc: 0.7578 - val_loss: 0.5015 - val_acc: 0.7567\n",
      "3-conv-32-nodes-0-dense-1569281678\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/3\n",
      "17462/17462 [==============================] - 3s 188us/sample - loss: 0.6513 - acc: 0.6054 - val_loss: 0.5819 - val_acc: 0.7035\n",
      "Epoch 2/3\n",
      "17462/17462 [==============================] - 3s 161us/sample - loss: 0.5588 - acc: 0.7165 - val_loss: 0.5330 - val_acc: 0.7396\n",
      "Epoch 3/3\n",
      "17462/17462 [==============================] - 3s 161us/sample - loss: 0.5124 - acc: 0.7500 - val_loss: 0.4980 - val_acc: 0.7603\n",
      "1-conv-64-nodes-0-dense-1569281695\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/3\n",
      "17462/17462 [==============================] - 3s 167us/sample - loss: 0.6153 - acc: 0.6605 - val_loss: 0.5708 - val_acc: 0.7138\n",
      "Epoch 2/3\n",
      "17462/17462 [==============================] - 2s 141us/sample - loss: 0.5433 - acc: 0.7269 - val_loss: 0.5545 - val_acc: 0.7174\n",
      "Epoch 3/3\n",
      "17462/17462 [==============================] - 3s 143us/sample - loss: 0.5120 - acc: 0.7524 - val_loss: 0.5292 - val_acc: 0.7425\n",
      "2-conv-64-nodes-0-dense-1569281712\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/3\n",
      "17462/17462 [==============================] - 3s 198us/sample - loss: 0.6367 - acc: 0.6305 - val_loss: 0.5687 - val_acc: 0.7173\n",
      "Epoch 2/3\n",
      "17462/17462 [==============================] - 3s 188us/sample - loss: 0.5421 - acc: 0.7308 - val_loss: 0.5230 - val_acc: 0.7441\n",
      "Epoch 3/3\n",
      "17462/17462 [==============================] - 3s 175us/sample - loss: 0.4983 - acc: 0.7600 - val_loss: 0.5020 - val_acc: 0.7543\n",
      "3-conv-64-nodes-0-dense-1569281730\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/3\n",
      "17462/17462 [==============================] - 4s 221us/sample - loss: 0.6356 - acc: 0.6297 - val_loss: 0.5919 - val_acc: 0.6861\n",
      "Epoch 2/3\n",
      "17462/17462 [==============================] - 3s 183us/sample - loss: 0.5355 - acc: 0.7343 - val_loss: 0.5005 - val_acc: 0.7595\n",
      "Epoch 3/3\n",
      "17462/17462 [==============================] - 3s 181us/sample - loss: 0.4826 - acc: 0.7690 - val_loss: 0.4807 - val_acc: 0.7750\n",
      "1-conv-128-nodes-0-dense-1569281752\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/3\n",
      "17462/17462 [==============================] - 4s 209us/sample - loss: 0.6273 - acc: 0.6553 - val_loss: 0.5710 - val_acc: 0.7227\n",
      "Epoch 2/3\n",
      "17462/17462 [==============================] - 3s 185us/sample - loss: 0.5476 - acc: 0.7284 - val_loss: 0.5441 - val_acc: 0.7337\n",
      "Epoch 3/3\n",
      "17462/17462 [==============================] - 3s 188us/sample - loss: 0.5050 - acc: 0.7576 - val_loss: 0.5246 - val_acc: 0.7457\n",
      "2-conv-128-nodes-0-dense-1569281773\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/3\n",
      "17462/17462 [==============================] - 5s 261us/sample - loss: 0.6381 - acc: 0.6352 - val_loss: 0.5766 - val_acc: 0.7066\n",
      "Epoch 2/3\n",
      "17462/17462 [==============================] - 4s 230us/sample - loss: 0.5488 - acc: 0.7249 - val_loss: 0.5213 - val_acc: 0.7431\n",
      "Epoch 3/3\n",
      "17462/17462 [==============================] - 4s 231us/sample - loss: 0.4955 - acc: 0.7611 - val_loss: 0.4948 - val_acc: 0.7634\n",
      "3-conv-128-nodes-0-dense-1569281796\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/3\n",
      "17462/17462 [==============================] - 5s 286us/sample - loss: 0.6570 - acc: 0.6049 - val_loss: 0.6245 - val_acc: 0.6464\n",
      "Epoch 2/3\n",
      "17462/17462 [==============================] - 4s 257us/sample - loss: 0.5529 - acc: 0.7198 - val_loss: 0.5189 - val_acc: 0.7484\n",
      "Epoch 3/3\n",
      "17462/17462 [==============================] - 4s 258us/sample - loss: 0.4825 - acc: 0.7692 - val_loss: 0.4936 - val_acc: 0.7626\n",
      "1-conv-32-nodes-1-dense-1569281822\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/3\n",
      "17462/17462 [==============================] - 3s 164us/sample - loss: 0.6220 - acc: 0.6514 - val_loss: 0.5641 - val_acc: 0.7138\n",
      "Epoch 2/3\n",
      "17462/17462 [==============================] - 2s 138us/sample - loss: 0.5346 - acc: 0.7367 - val_loss: 0.5336 - val_acc: 0.7328\n",
      "Epoch 3/3\n",
      "17462/17462 [==============================] - 2s 136us/sample - loss: 0.4920 - acc: 0.7627 - val_loss: 0.5317 - val_acc: 0.7385\n",
      "2-conv-32-nodes-1-dense-1569281842\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/3\n",
      "17462/17462 [==============================] - 3s 184us/sample - loss: 0.6238 - acc: 0.6424 - val_loss: 0.5537 - val_acc: 0.7243\n",
      "Epoch 2/3\n",
      "17462/17462 [==============================] - 3s 156us/sample - loss: 0.5184 - acc: 0.7461 - val_loss: 0.5224 - val_acc: 0.7485\n",
      "Epoch 3/3\n",
      "17462/17462 [==============================] - 3s 156us/sample - loss: 0.4801 - acc: 0.7720 - val_loss: 0.4975 - val_acc: 0.7608\n",
      "3-conv-32-nodes-1-dense-1569281864\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/3\n",
      "17462/17462 [==============================] - 4s 204us/sample - loss: 0.6410 - acc: 0.6262 - val_loss: 0.5861 - val_acc: 0.6954\n",
      "Epoch 2/3\n",
      "17462/17462 [==============================] - 3s 170us/sample - loss: 0.5626 - acc: 0.7095 - val_loss: 0.5516 - val_acc: 0.7185\n",
      "Epoch 3/3\n",
      "17462/17462 [==============================] - 3s 170us/sample - loss: 0.5118 - acc: 0.7472 - val_loss: 0.5211 - val_acc: 0.7449\n",
      "1-conv-64-nodes-1-dense-1569281888\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/3\n",
      "17462/17462 [==============================] - 4s 219us/sample - loss: 0.6179 - acc: 0.6632 - val_loss: 0.5577 - val_acc: 0.7219\n",
      "Epoch 2/3\n",
      "17462/17462 [==============================] - 3s 191us/sample - loss: 0.5294 - acc: 0.7373 - val_loss: 0.5583 - val_acc: 0.7138\n",
      "Epoch 3/3\n",
      "17462/17462 [==============================] - 3s 187us/sample - loss: 0.4817 - acc: 0.7691 - val_loss: 0.5324 - val_acc: 0.7340\n",
      "2-conv-64-nodes-1-dense-1569281913\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/3\n",
      "17462/17462 [==============================] - 4s 232us/sample - loss: 0.6342 - acc: 0.6298 - val_loss: 0.5927 - val_acc: 0.6776\n",
      "Epoch 2/3\n",
      "17462/17462 [==============================] - 3s 197us/sample - loss: 0.5364 - acc: 0.7294 - val_loss: 0.5123 - val_acc: 0.7480\n",
      "Epoch 3/3\n",
      "17462/17462 [==============================] - 3s 198us/sample - loss: 0.4784 - acc: 0.7710 - val_loss: 0.6455 - val_acc: 0.6821\n",
      "3-conv-64-nodes-1-dense-1569281940\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/3\n",
      "17462/17462 [==============================] - 4s 247us/sample - loss: 0.6595 - acc: 0.5941 - val_loss: 0.6067 - val_acc: 0.6701\n",
      "Epoch 2/3\n",
      "17462/17462 [==============================] - 4s 209us/sample - loss: 0.5745 - acc: 0.7023 - val_loss: 0.5371 - val_acc: 0.7316\n",
      "Epoch 3/3\n",
      "17462/17462 [==============================] - 4s 206us/sample - loss: 0.5086 - acc: 0.7501 - val_loss: 0.4950 - val_acc: 0.7620\n",
      "1-conv-128-nodes-1-dense-1569281968\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/3\n",
      "17462/17462 [==============================] - 6s 353us/sample - loss: 0.6949 - acc: 0.5655 - val_loss: 0.6774 - val_acc: 0.5685\n",
      "Epoch 2/3\n",
      "17462/17462 [==============================] - 6s 317us/sample - loss: 0.6329 - acc: 0.6692 - val_loss: 0.6077 - val_acc: 0.6998\n",
      "Epoch 3/3\n",
      "17462/17462 [==============================] - 6s 322us/sample - loss: 0.5722 - acc: 0.7249 - val_loss: 0.5783 - val_acc: 0.7206\n",
      "2-conv-128-nodes-1-dense-1569282003\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17462/17462 [==============================] - 6s 326us/sample - loss: 0.6608 - acc: 0.5949 - val_loss: 0.6265 - val_acc: 0.6633\n",
      "Epoch 2/3\n",
      "17462/17462 [==============================] - 5s 286us/sample - loss: 0.5855 - acc: 0.6908 - val_loss: 0.5621 - val_acc: 0.7103\n",
      "Epoch 3/3\n",
      "17462/17462 [==============================] - 5s 286us/sample - loss: 0.5261 - acc: 0.7389 - val_loss: 0.5251 - val_acc: 0.7388\n",
      "3-conv-128-nodes-1-dense-1569282037\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/3\n",
      "17462/17462 [==============================] - 6s 340us/sample - loss: 0.6440 - acc: 0.6179 - val_loss: 0.5987 - val_acc: 0.6777\n",
      "Epoch 2/3\n",
      "17462/17462 [==============================] - 5s 300us/sample - loss: 0.5436 - acc: 0.7264 - val_loss: 0.5349 - val_acc: 0.7312\n",
      "Epoch 3/3\n",
      "17462/17462 [==============================] - 5s 293us/sample - loss: 0.4754 - acc: 0.7717 - val_loss: 0.4821 - val_acc: 0.7636\n",
      "1-conv-32-nodes-2-dense-1569282073\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/3\n",
      "17462/17462 [==============================] - 3s 196us/sample - loss: 0.6304 - acc: 0.6400 - val_loss: 0.5659 - val_acc: 0.7104\n",
      "Epoch 2/3\n",
      "17462/17462 [==============================] - 3s 162us/sample - loss: 0.5318 - acc: 0.7345 - val_loss: 0.5664 - val_acc: 0.7078\n",
      "Epoch 3/3\n",
      "17462/17462 [==============================] - 3s 161us/sample - loss: 0.4824 - acc: 0.7697 - val_loss: 0.5498 - val_acc: 0.7263\n",
      "2-conv-32-nodes-2-dense-1569282102\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/3\n",
      "17462/17462 [==============================] - 4s 216us/sample - loss: 0.6228 - acc: 0.6448 - val_loss: 0.5564 - val_acc: 0.7161\n",
      "Epoch 2/3\n",
      "17462/17462 [==============================] - 3s 176us/sample - loss: 0.5207 - acc: 0.7408 - val_loss: 0.5182 - val_acc: 0.7489\n",
      "Epoch 3/3\n",
      "17462/17462 [==============================] - 3s 175us/sample - loss: 0.4805 - acc: 0.7706 - val_loss: 0.5112 - val_acc: 0.7479\n",
      "3-conv-32-nodes-2-dense-1569282132\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/3\n",
      "17462/17462 [==============================] - 4s 235us/sample - loss: 0.6760 - acc: 0.5693 - val_loss: 0.6569 - val_acc: 0.6053\n",
      "Epoch 2/3\n",
      "17462/17462 [==============================] - 3s 189us/sample - loss: 0.5929 - acc: 0.6841 - val_loss: 0.5758 - val_acc: 0.6936\n",
      "Epoch 3/3\n",
      "17462/17462 [==============================] - 3s 193us/sample - loss: 0.5225 - acc: 0.7384 - val_loss: 0.4993 - val_acc: 0.7596\n",
      "1-conv-64-nodes-2-dense-1569282165\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/3\n",
      "17462/17462 [==============================] - 4s 238us/sample - loss: 0.6134 - acc: 0.6613 - val_loss: 0.5549 - val_acc: 0.7223\n",
      "Epoch 2/3\n",
      "17462/17462 [==============================] - 4s 207us/sample - loss: 0.5198 - acc: 0.7410 - val_loss: 0.5701 - val_acc: 0.7108\n",
      "Epoch 3/3\n",
      "17462/17462 [==============================] - 4s 214us/sample - loss: 0.4705 - acc: 0.7749 - val_loss: 0.5726 - val_acc: 0.7115\n",
      "2-conv-64-nodes-2-dense-1569282198\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/3\n",
      "17462/17462 [==============================] - 5s 268us/sample - loss: 0.6476 - acc: 0.6050 - val_loss: 0.6029 - val_acc: 0.6693\n",
      "Epoch 2/3\n",
      "17462/17462 [==============================] - 4s 228us/sample - loss: 0.5518 - acc: 0.7189 - val_loss: 0.5480 - val_acc: 0.7227\n",
      "Epoch 3/3\n",
      "17462/17462 [==============================] - 4s 224us/sample - loss: 0.4956 - acc: 0.7594 - val_loss: 0.5212 - val_acc: 0.7429\n",
      "3-conv-64-nodes-2-dense-1569282235\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/3\n",
      "17462/17462 [==============================] - 5s 269us/sample - loss: 0.6825 - acc: 0.5459 - val_loss: 0.6741 - val_acc: 0.5770\n",
      "Epoch 2/3\n",
      "17462/17462 [==============================] - 4s 220us/sample - loss: 0.6019 - acc: 0.6733 - val_loss: 0.5394 - val_acc: 0.7276\n",
      "Epoch 3/3\n",
      "17462/17462 [==============================] - 4s 220us/sample - loss: 0.5116 - acc: 0.7453 - val_loss: 0.4980 - val_acc: 0.7608\n",
      "1-conv-128-nodes-2-dense-1569282272\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/3\n",
      "17462/17462 [==============================] - 7s 382us/sample - loss: 0.6218 - acc: 0.6506 - val_loss: 0.5572 - val_acc: 0.7213\n",
      "Epoch 2/3\n",
      "17462/17462 [==============================] - 6s 365us/sample - loss: 0.5178 - acc: 0.7461 - val_loss: 0.5416 - val_acc: 0.7261\n",
      "Epoch 3/3\n",
      "17462/17462 [==============================] - 6s 364us/sample - loss: 0.4427 - acc: 0.7905 - val_loss: 0.5468 - val_acc: 0.7237\n",
      "2-conv-128-nodes-2-dense-1569282317\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/3\n",
      "17462/17462 [==============================] - 6s 366us/sample - loss: 0.6235 - acc: 0.6472 - val_loss: 0.5728 - val_acc: 0.7060\n",
      "Epoch 2/3\n",
      "17462/17462 [==============================] - 6s 331us/sample - loss: 0.5316 - acc: 0.7342 - val_loss: 0.5459 - val_acc: 0.7181\n",
      "Epoch 3/3\n",
      "17462/17462 [==============================] - 6s 358us/sample - loss: 0.4803 - acc: 0.7704 - val_loss: 0.4904 - val_acc: 0.7630\n",
      "3-conv-128-nodes-2-dense-1569282364\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/3\n",
      "17462/17462 [==============================] - 6s 348us/sample - loss: 0.6669 - acc: 0.5797 - val_loss: 0.6347 - val_acc: 0.6343\n",
      "Epoch 2/3\n",
      "17462/17462 [==============================] - 5s 296us/sample - loss: 0.5778 - acc: 0.6973 - val_loss: 0.5670 - val_acc: 0.7038\n",
      "Epoch 3/3\n",
      "17462/17462 [==============================] - 5s 297us/sample - loss: 0.4988 - acc: 0.7531 - val_loss: 0.5155 - val_acc: 0.7364\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            print(NAME)\n",
    "\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer_size, (3, 3), input_shape=X.shape[1:]))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            for l in range(conv_layer-1):\n",
    "                model.add(Conv2D(layer_size, (3, 3)))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            model.add(Flatten())\n",
    "\n",
    "            for _ in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation('relu'))\n",
    "\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "\n",
    "            tensorboard = TensorBoard(log_dir=\"abunchoflogs/{}\".format(NAME))\n",
    "\n",
    "            model.compile(loss='binary_crossentropy',\n",
    "                          optimizer='adam',\n",
    "                          metrics=['accuracy'],\n",
    "                          )\n",
    "\n",
    "            model.fit(X, y,\n",
    "                      batch_size=32,\n",
    "                      epochs=3,\n",
    "                      validation_split=0.3,\n",
    "                      callbacks=[tensorboard])\n",
    "\n",
    "model.save('64x3-CNN.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
